{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a100c321",
   "metadata": {},
   "source": [
    "This tool is built to create reports on any topic requested using the climate tracker database\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import BaseOutputParser\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c1a76",
   "metadata": {},
   "source": [
    "**play around whith which models work best for different parts of the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "basic_model = ChatOpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.6\n",
    ")\n",
    "\n",
    "larger_context_model = ChatOpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac2c73",
   "metadata": {},
   "source": [
    "#### 1.1 Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b82d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the template generating LLM\n",
    "template_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to create a template for the structure of a 1 page report on {topic}. \n",
    "     \n",
    "     Here are some example templates to base your response on:\n",
    "        ##METADATA \n",
    "\n",
    "        *Country: \n",
    "\n",
    "        ##REPORT \n",
    "\n",
    "        Q1: What are the relevant background information for indicator X, Y or Z? \n",
    "        … \n",
    "        Question N (CHALLENGING): How has the legislation of this country changed in the past 50 years? \n",
    "        \n",
    "     \n",
    "        ##TOPIC: Just transition \n",
    "\n",
    "        *Countries with relevant information: … \n",
    "\n",
    "        ##REPORT \n",
    "\n",
    "        Q1: Which countries have made plans for a just energetic transition? \n",
    "\n",
    "        A: Country A [citation], B [citation] and C [citation] have a similar law. They all promise X, Y and Z. On the other hand, the following countries … differ because … \n",
    "        A: … \n",
    "        \n",
    "        A law meets this criterion if it includes a clear statement to meet the goals of the Paris Agreement \n",
    "        OR a national long-term decarbonisation target.\n",
    "        \n",
    "    Respond with only the template of the {topic} report and nothing else.\"\"\"),\n",
    "    (\"human\", \"Context: {topic}\")\n",
    "])\n",
    "\n",
    "# Seperate template into sub-sections USE LOW POWER LMMM\n",
    "section_seperator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to extract the subsections from {template}.         \n",
    "    Respond with only the template subsections nothing else.\"\"\"),\n",
    "# SPECIFY HOW TO STRUCUTRE SUBSECTIONS SO CAN BE EXTRACTED EASILY\n",
    "    (\"human\", \"{template}\")\n",
    "])\n",
    "\n",
    "# For the hypothetical response generating LLM\n",
    "hypothetical_response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to generate a hypothetical response for the following question: {subsection}. \n",
    "    The response should be based on the template {template}, a template for a report on topic {topic}.\n",
    "    \n",
    "    Respond with only the hypothetical response nothing else.\"\"\"),\n",
    "    (\"human\", \"{subsection}, {template}, {topic}\")\n",
    "])\n",
    "# Prompts for each of the sub-section models\n",
    "subsection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to create a one paragraph {subsection} as part of a report on {topic}.\n",
    "    Use only information on {context} to create the paragraph.\n",
    "    The paragraph should be concise and informative, summarizing the key points relevant to the subsection.     \n",
    "    Respond with only the paragraph for that subsections nothing else.\"\"\"),\n",
    "    (\"human\", \"{subsection}, {context}, {topic}\")\n",
    "])\n",
    "\n",
    "\n",
    "# THIS COULD BE DONE WITHOUT USING AN LLM???\n",
    "# Prompt for the compling model\n",
    "compiling_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to compile the following subsections {all_subsections}.\n",
    "    The report should be structured according to the template {template}.\n",
    "    The report must match exactly the template structure.\n",
    "    \n",
    "    Respond with only the compiled report nothing else.\"\"\"),\n",
    "    (\"human\", \"{all_subsections}, {template}\")\n",
    "])\n",
    "\n",
    "# Prompt for the checking model\n",
    "checking_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to check the following subsections {all_subsections} for consistency and completeness.\n",
    "    Also ensure that the report {report} matches the template {template}.\n",
    "    Also ensure that the report is related to the topic {topic}.\n",
    "     \n",
    "    If \n",
    "        1) One of the subsections appears incorrect or incomplete → output ONLY: (**subsection name**), incomplete\n",
    "        2) The report does not match the template → output ONLY: not match\n",
    "        3) The report is not related to the topic → output ONLY: not related\n",
    "        4) Everything is correct → output ONLY: ok\n",
    "     \n",
    "    Respond with only the result of the check (ok, not related, not match, (**subsection name**) incomplete) nothing else.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{all_subsections}, {template}, {report}, {topic}\")\n",
    "])\n",
    "\n",
    "# Prompt for the rewrite subsection model\n",
    "rewrite_subsection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert legal analyst specializing in climate legislation. \n",
    "    Your task is to rewrite the following subsection {subsection} to make it more complete and consistent.\n",
    "    Use the template {template} as a guide for the structure.\n",
    "    The rewritten subsection should be concise and informative, summarizing the key points relevant to the subsection.\n",
    "    \n",
    "    Respond with only the rewritten subsection nothing else.\"\"\"),\n",
    "    (\"human\", \"{subsection}, {template}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3453fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. template, 2. ask human if they like template, 3. if yes, then continue with the next steps, if no, then rewrite template"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
