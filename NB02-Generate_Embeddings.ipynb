{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1fc2d4",
   "metadata": {},
   "source": [
    "# Generating Embeddings\n",
    "\n",
    "In this notebook we will generate embeddings using both the ClimateBERT model and Word2Vec using the following structure:\n",
    "\n",
    "1. Reading the data and documents from the database\n",
    "2. Download and store the embeddings models\n",
    "3. Create a new table for storing the embeddings and some original data we want. Generate embeddings using both models and store them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71e567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pgai\n",
    "import torch\n",
    "import glob\n",
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "tqdm.pandas() #check if i should put it here\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "#connecting to the database\n",
    "load_dotenv() #loads the .env file into os.environ\n",
    "engine = create_engine(os.getenv(\"DB_URL\"))\n",
    "\n",
    "#create session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "#word2vec model imports\n",
    "import psycopg2\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load\n",
    "from gensim.utils import simple_preprocess\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "#importing functions\n",
    "from functions import generate_embeddings_for_text, embed_and_store_all_embeddings, train_custom_word2vec_from_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802840d",
   "metadata": {},
   "source": [
    "## 1. Read the data from the database\n",
    "\n",
    "So it's easier to access the data in case the kernel crashes and had to re-run the codes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9578b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_metadata.collection_summary</th>\n",
       "      <th>document_metadata.collection_title</th>\n",
       "      <th>document_metadata.corpus_type_name</th>\n",
       "      <th>document_metadata.corpus_import_id</th>\n",
       "      <th>document_metadata.category</th>\n",
       "      <th>document_metadata.description</th>\n",
       "      <th>document_metadata.document_title</th>\n",
       "      <th>document_metadata.family_import_id</th>\n",
       "      <th>document_metadata.family_slug</th>\n",
       "      <th>...</th>\n",
       "      <th>pipeline_metadata.parser_metadata.azure_model_id</th>\n",
       "      <th>pipeline_metadata.parser_metadata.parsing_date</th>\n",
       "      <th>text_block.text_block_id</th>\n",
       "      <th>text_block.language</th>\n",
       "      <th>text_block.type</th>\n",
       "      <th>text_block.type_confidence</th>\n",
       "      <th>text_block.coords</th>\n",
       "      <th>text_block.page_number</th>\n",
       "      <th>text_block.text</th>\n",
       "      <th>text_block.index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLW.document.i00000964.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The NAP is the adaptation component of the ...</td>\n",
       "      <td>Albania’s National Adaptation Plan First - pro...</td>\n",
       "      <td>CCLW.family.10661.0</td>\n",
       "      <td>national-adaptation-planning-nap-to-climate-ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2024-05-07T08:46:18.237130</td>\n",
       "      <td>1924</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{444.83040000000005,404.84159999999997},{523....</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Ministry of Tourism and Environment</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLW.document.i00000964.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The NAP is the adaptation component of the ...</td>\n",
       "      <td>Albania’s National Adaptation Plan First - pro...</td>\n",
       "      <td>CCLW.family.10661.0</td>\n",
       "      <td>national-adaptation-planning-nap-to-climate-ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2024-05-07T08:46:18.237130</td>\n",
       "      <td>1925</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{523.6128,404.84159999999997},{584.6472000000...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Completed in 2020</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLW.document.i00000964.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The NAP is the adaptation component of the ...</td>\n",
       "      <td>Albania’s National Adaptation Plan First - pro...</td>\n",
       "      <td>CCLW.family.10661.0</td>\n",
       "      <td>national-adaptation-planning-nap-to-climate-ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2024-05-07T08:46:18.237130</td>\n",
       "      <td>1926</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{584.6472000000001,404.84159999999997},{760.6...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>https://www.osce.org/secretariat/4 84148</td>\n",
       "      <td>1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLW.document.i00000964.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The NAP is the adaptation component of the ...</td>\n",
       "      <td>Albania’s National Adaptation Plan First - pro...</td>\n",
       "      <td>CCLW.family.10661.0</td>\n",
       "      <td>national-adaptation-planning-nap-to-climate-ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2024-05-07T08:46:18.237130</td>\n",
       "      <td>1927</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{67.2624,463.7952},{98.4888,463.7952},{98.488...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLW.document.i00000964.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The NAP is the adaptation component of the ...</td>\n",
       "      <td>Albania’s National Adaptation Plan First - pro...</td>\n",
       "      <td>CCLW.family.10661.0</td>\n",
       "      <td>national-adaptation-planning-nap-to-climate-ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2024-05-07T08:46:18.237130</td>\n",
       "      <td>1928</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{98.4888,463.7952},{323.4744,463.7952},{323.4...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>BRIdging the GAp for Innovations in Disaster r...</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document_id document_metadata.collection_summary  \\\n",
       "0  CCLW.document.i00000964.n0000                                 None   \n",
       "1  CCLW.document.i00000964.n0000                                 None   \n",
       "2  CCLW.document.i00000964.n0000                                 None   \n",
       "3  CCLW.document.i00000964.n0000                                 None   \n",
       "4  CCLW.document.i00000964.n0000                                 None   \n",
       "\n",
       "  document_metadata.collection_title document_metadata.corpus_type_name  \\\n",
       "0                               None                  Laws and Policies   \n",
       "1                               None                  Laws and Policies   \n",
       "2                               None                  Laws and Policies   \n",
       "3                               None                  Laws and Policies   \n",
       "4                               None                  Laws and Policies   \n",
       "\n",
       "  document_metadata.corpus_import_id document_metadata.category  \\\n",
       "0        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "1        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "2        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "3        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "4        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "\n",
       "                       document_metadata.description  \\\n",
       "0  <p>The NAP is the adaptation component of the ...   \n",
       "1  <p>The NAP is the adaptation component of the ...   \n",
       "2  <p>The NAP is the adaptation component of the ...   \n",
       "3  <p>The NAP is the adaptation component of the ...   \n",
       "4  <p>The NAP is the adaptation component of the ...   \n",
       "\n",
       "                    document_metadata.document_title  \\\n",
       "0  Albania’s National Adaptation Plan First - pro...   \n",
       "1  Albania’s National Adaptation Plan First - pro...   \n",
       "2  Albania’s National Adaptation Plan First - pro...   \n",
       "3  Albania’s National Adaptation Plan First - pro...   \n",
       "4  Albania’s National Adaptation Plan First - pro...   \n",
       "\n",
       "  document_metadata.family_import_id  \\\n",
       "0                CCLW.family.10661.0   \n",
       "1                CCLW.family.10661.0   \n",
       "2                CCLW.family.10661.0   \n",
       "3                CCLW.family.10661.0   \n",
       "4                CCLW.family.10661.0   \n",
       "\n",
       "                       document_metadata.family_slug  ...  \\\n",
       "0  national-adaptation-planning-nap-to-climate-ch...  ...   \n",
       "1  national-adaptation-planning-nap-to-climate-ch...  ...   \n",
       "2  national-adaptation-planning-nap-to-climate-ch...  ...   \n",
       "3  national-adaptation-planning-nap-to-climate-ch...  ...   \n",
       "4  national-adaptation-planning-nap-to-climate-ch...  ...   \n",
       "\n",
       "  pipeline_metadata.parser_metadata.azure_model_id  \\\n",
       "0                                prebuilt-document   \n",
       "1                                prebuilt-document   \n",
       "2                                prebuilt-document   \n",
       "3                                prebuilt-document   \n",
       "4                                prebuilt-document   \n",
       "\n",
       "  pipeline_metadata.parser_metadata.parsing_date text_block.text_block_id  \\\n",
       "0                     2024-05-07T08:46:18.237130                     1924   \n",
       "1                     2024-05-07T08:46:18.237130                     1925   \n",
       "2                     2024-05-07T08:46:18.237130                     1926   \n",
       "3                     2024-05-07T08:46:18.237130                     1927   \n",
       "4                     2024-05-07T08:46:18.237130                     1928   \n",
       "\n",
       "  text_block.language text_block.type text_block.type_confidence  \\\n",
       "0                  en       TableCell                        1.0   \n",
       "1                  en       TableCell                        1.0   \n",
       "2                  en       TableCell                        1.0   \n",
       "3                  en       TableCell                        1.0   \n",
       "4                  en       TableCell                        1.0   \n",
       "\n",
       "                                   text_block.coords text_block.page_number  \\\n",
       "0  {{444.83040000000005,404.84159999999997},{523....                   59.0   \n",
       "1  {{523.6128,404.84159999999997},{584.6472000000...                   59.0   \n",
       "2  {{584.6472000000001,404.84159999999997},{760.6...                   59.0   \n",
       "3  {{67.2624,463.7952},{98.4888,463.7952},{98.488...                   59.0   \n",
       "4  {{98.4888,463.7952},{323.4744,463.7952},{323.4...                   59.0   \n",
       "\n",
       "                                     text_block.text text_block.index  \n",
       "0                Ministry of Tourism and Environment             1924  \n",
       "1                                  Completed in 2020             1925  \n",
       "2           https://www.osce.org/secretariat/4 84148             1926  \n",
       "3                                                  5             1927  \n",
       "4  BRIdging the GAp for Innovations in Disaster r...             1928  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the table\n",
    "df = pd.read_sql('SELECT * FROM climate_policy_radar WHERE \"document_metadata.geographies\" ~ \\'ALB\\';', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c3320",
   "metadata": {},
   "source": [
    "## 2. Embeddings generation\n",
    "\n",
    "### 2.1 Download and load ClimateBERT\n",
    "\n",
    "The code below will download and load the ClimateBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df15eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_LOCAL_DIR = os.getenv('EMBEDDING_MODEL_LOCAL_DIR')\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c822ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiefung/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/jessiefung/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.roberta.modeling_roberta because of the following error (look up to see its traceback):\npartially initialized module 'torch._dynamo' has no attribute 'decorators' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1967\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1966\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1381\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1354\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1325\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:929\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:994\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:43\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[32m     35\u001b[39m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     TokenClassifierOutput,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:63\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflash_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/integrations/flex_attention.py:45\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattention\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     41\u001b[39m         create_block_mask \u001b[38;5;28;01mas\u001b[39;00m create_block_causal_mask_flex,\n\u001b[32m     42\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mWrappedFlexAttention\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[33;43;03m    We are doing a singleton class so that flex attention is compiled once when it's first called.\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/integrations/flex_attention.py:60\u001b[39m, in \u001b[36mWrappedFlexAttention\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._instance\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;129m@torch\u001b[39m\u001b[43m.\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, training):\n\u001b[32m     62\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m    Initialize or update the singleton instance.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/torch/compiler/__init__.py:240\u001b[39m, in \u001b[36mdisable\u001b[39m\u001b[34m(fn, recursive)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03mThis function provides a decorator to disable compilation on a function.\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[33;03mIt also provides the option of recursively disabling called functions.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    recursive (optional): A boolean value indicating whether the disabling should be recursive.\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._dynamo.disable(fn, recursive)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:86\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# allowlist this for weights_only load of NJTs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m torch.serialization.add_safe_globals([\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dynamo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecorators\u001b[49m._DimRange])\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.manual_seed \u001b[38;5;129;01mis\u001b[39;00m torch.random.manual_seed:\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch._dynamo' has no attribute 'decorators' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download\u001b[39;00m\n\u001b[32m      2\u001b[39m tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, use_auth_token=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModelForMaskedLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Save it to a  local_models folder\u001b[39;00m\n\u001b[32m      6\u001b[39m tokenizer.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:568\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class.from_pretrained(\n\u001b[32m    565\u001b[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001b[32m    566\u001b[39m     )\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m     model_class = \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:388\u001b[39m, in \u001b[36m_get_model_class\u001b[39m\u001b[34m(config, model_mapping)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     supported_models = \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    390\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:770\u001b[39m, in \u001b[36m_LazyAutoMapping.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_mapping:\n\u001b[32m    769\u001b[39m     model_name = \u001b[38;5;28mself\u001b[39m._model_mapping[model_type]\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[32m    773\u001b[39m model_types = [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_mapping.items() \u001b[38;5;28;01mif\u001b[39;00m v == key.\u001b[34m__name__\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:784\u001b[39m, in \u001b[36m_LazyAutoMapping._load_attr_from_module\u001b[39m\u001b[34m(self, model_type, attr)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m    783\u001b[39m     \u001b[38;5;28mself\u001b[39m._modules[module_name] = importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransformers.models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:700\u001b[39m, in \u001b[36mgetattribute_from_module\u001b[39m\u001b[34m(module, attr)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    701\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1955\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1953\u001b[39m     value = Placeholder\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1956\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1969\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1969\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1970\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1971\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1972\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to import transformers.models.roberta.modeling_roberta because of the following error (look up to see its traceback):\npartially initialized module 'torch._dynamo' has no attribute 'decorators' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Download\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "\n",
    "# Save it to a  local_models folder\n",
    "tokenizer.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "model.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at local_model/climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "climatebert_tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "climatebert_model = AutoModel.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256326f",
   "metadata": {},
   "source": [
    "### 2.2 Download and load Word2Vec\n",
    "\n",
    "This Word2Vec model is untrained. We will check if training is necessary and use the trained model if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading pretrained Word2Vec model: word2vec-google-news-300\n",
      "✅ Model loaded!\n",
      "[('climate_change', 0.6569507122039795), ('Climate', 0.6230838298797607), ('climates', 0.6195024251937866), ('global_warming', 0.6047458648681641), ('environment', 0.6009922027587891), ('climatic', 0.5555011630058289), ('climatic_conditions', 0.5207005143165588), ('ambassador_Brice_Lalonde', 0.5172268152236938), ('Global_warming', 0.5048916339874268), ('Climate_Change', 0.4955976605415344)]\n"
     ]
    }
   ],
   "source": [
    "# Choose a pretrained Word2Vec model\n",
    "model_name = \"word2vec-google-news-300\"\n",
    "\n",
    "# Download and load the model\n",
    "print(f\"🔄 Loading pretrained Word2Vec model: {model_name}\")\n",
    "word2vec_model = load(model_name)\n",
    "print(\"✅ Model loaded!\")\n",
    "\n",
    "# Example: check similarity\n",
    "print(word2vec_model.most_similar(\"climate\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182e84d",
   "metadata": {},
   "source": [
    "Now check if the Word2Vec model is able to cover climate-specific words in the climate policy radar. If they cannot be covered we would have to train the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9741de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Top OOV words not in Word2Vec:\n",
      "of: 3362\n",
      "and: 2566\n",
      "to: 1565\n",
      "albania: 310\n",
      "albanian: 159\n",
      "dcm: 144\n",
      "wem: 136\n",
      "necp: 79\n",
      "modelling: 72\n",
      "ktoe: 69\n",
      "implem: 57\n",
      "meur: 43\n",
      "tirana: 41\n",
      "ghgs: 33\n",
      "gwp: 33\n",
      "adriatic: 32\n",
      "montenegro: 28\n",
      "oshee: 23\n",
      "vlora: 23\n",
      "albgaz: 23\n",
      "pams: 18\n",
      "neeap: 17\n",
      "mva: 17\n",
      "lulucf: 17\n",
      "unfccc: 16\n",
      "aee: 15\n",
      "ionian: 15\n",
      "ippu: 15\n",
      "programme: 15\n",
      "smes: 14\n",
      "entso: 13\n",
      "instat: 13\n",
      "tpes: 13\n",
      "wbif: 13\n",
      "alkogap: 12\n",
      "gwh: 12\n",
      "elbasan: 12\n",
      "hfc: 12\n",
      "ktco: 11\n",
      "labelling: 10\n",
      "dumrea: 10\n",
      "hpp: 9\n",
      "iap: 9\n",
      "mmr: 9\n",
      "nzeb: 9\n",
      "balkans: 9\n",
      "escos: 9\n",
      "ebrd: 8\n",
      "kfw: 8\n",
      "mte: 8\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \"text_block.text\"\n",
    "FROM climate_policy_radar\n",
    "WHERE \"text_block.text\" IS NOT NULL\n",
    "LIMIT 10000;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "# 3. Tokenize and gather all unique words\n",
    "all_tokens = []\n",
    "for text in df['text_block.text']:\n",
    "    tokens = simple_preprocess(text)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# 4. Compare to Word2Vec vocabulary\n",
    "vocab = set(word2vec_model.key_to_index)\n",
    "oov_words = [token for token in all_tokens if token not in vocab]\n",
    "\n",
    "# 5. Count top missing words\n",
    "oov_counter = Counter(oov_words)\n",
    "most_common_oov = oov_counter.most_common(50)\n",
    "\n",
    "# 6. Display\n",
    "print(\"❌ Top OOV words not in Word2Vec:\")\n",
    "for word, count in most_common_oov:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dccfd",
   "metadata": {},
   "source": [
    "We can see there are some terms i.e. abbreviations and locations that are absent in word2vec. We'll train the model and also make sure the embeddings are in 768 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7987f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the function to train the model so the absent words can be added\n",
    "\n",
    "texts = df['text_block.text'].dropna().tolist()\n",
    "\n",
    "important_terms = [\n",
    "    \"albania\", \"albanian\", \"unfccc\", \"gwp\", \"ghgs\", \"necp\", \"modelling\", \"ktoe\", \n",
    "    \"tirana\", \"vlora\", \"adriatic\", \"ionian\", \"montenegro\", \"albgaz\", \"oshee\",\n",
    "    \"lulucf\", \"neeap\", \"wbif\", \"instat\", \"tpes\", \"gwh\", \"nzeb\", \"entso\", \"smes\"\n",
    "]\n",
    "\n",
    "model = train_custom_word2vec_from_texts(\n",
    "    texts=texts,\n",
    "    force_include_words=important_terms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c97d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'albania' in vocab | Dim: 768\n",
      "✅ 'unfccc' in vocab | Dim: 768\n",
      "✅ 'gwp' in vocab | Dim: 768\n",
      "✅ 'oshee' in vocab | Dim: 768\n",
      "✅ 'tirana' in vocab | Dim: 768\n",
      "✅ 'ktoe' in vocab | Dim: 768\n",
      "✅ 'neeap' in vocab | Dim: 768\n",
      "✅ 'smes' in vocab | Dim: 768\n"
     ]
    }
   ],
   "source": [
    "# DOUBLE CHECK IF THE MODEL IS LOADED CORRECTLY\n",
    "# Load model if needed\n",
    "\n",
    "model = Word2Vec.load(\"./local_model/custom_word2vec_768.model\")\n",
    "\n",
    "\n",
    "# List of words you want to check\n",
    "words_to_check = [\n",
    "    \"albania\", \"unfccc\", \"gwp\", \"oshee\", \"tirana\", \"ktoe\", \"neeap\", \"smes\"\n",
    "]\n",
    "\n",
    "# Check dimensionality and coverage\n",
    "for word in words_to_check:\n",
    "    if word in model.wv:\n",
    "        vec = model.wv[word]\n",
    "        print(f\"✅ '{word}' in vocab | Dim: {len(vec)}\")\n",
    "    else:\n",
    "        print(f\"❌ '{word}' NOT in vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c8220",
   "metadata": {},
   "source": [
    "Check exisiting documents' country so when they are embedded and they are grouped together and uploaded to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   document_metadata.geographies\n",
      "0                          {SRB}\n",
      "1                          {MKD}\n",
      "2                          {GBR}\n",
      "3                          {TUV}\n",
      "4                          {FRA}\n",
      "5                          {ALB}\n",
      "6                          {EUR}\n",
      "7                          {MNE}\n",
      "8                          {AZE}\n",
      "9                          {CAN}\n",
      "10                         {JPN}\n",
      "11                         {BRA}\n",
      "12                         {DEU}\n",
      "13                         {XKX}\n",
      "14                         {CHN}\n",
      "15                         {ZAF}\n",
      "16                         {BIH}\n",
      "17                         {IRL}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT \"document_metadata.geographies\"\n",
    "FROM climate_policy_radar\n",
    "WHERE \"document_metadata.geographies\" IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "geos = pd.read_sql(query, engine)\n",
    "print(geos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f8ea8",
   "metadata": {},
   "source": [
    "## 3. Embedding all documents for all countries\n",
    "\n",
    "Generate embeddings for all documents and upload them into the database.\n",
    "\n",
    "**IMPORTANT THING TO DO BEFORE RUNNING THE CODE BELOW:**\n",
    "\n",
    "A new table is needed, this will be created through the create_table.sql file. Steps to run it:\n",
    "\n",
    "1. Go to create_table.sql and run the query to create the table\n",
    "2. Remember to select the Postgres Server at the bottom, and highlight the code and right click to run query\n",
    "\n",
    "\n",
    "This will create a new table in the database. The file also includes a *\"DROP TABLE IF EXISTS document_embeddings;\"* line if the table does not appear. Try not to use it after the data are uploaded because it will drop all exisisting data. Use with cautious. After creating the table, then run the code below to generate embeddings and store them into the database. This will take around 2 hours to finish running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding and storing all embeddings in the database\n",
    "\n",
    "embed_and_store_all_embeddings(df, engine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
