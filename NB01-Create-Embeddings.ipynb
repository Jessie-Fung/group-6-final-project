{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83736cf2",
   "metadata": {},
   "source": [
    "# 1. Set up the Huggingface Climate Policy Radar dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dd415c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pgai\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "from datasets import load_dataset, Features, Value\n",
    "from functions import generate_embeddings_for_text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b6dc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5584b5620f14d96a0ca2896553bfc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131d87481a9a4cfa8fe581cfcc15b7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login using e.g. `huggingface-cli login` in command line to access this dataset\n",
    "\n",
    "ds = load_dataset(\"ClimatePolicyRadar/all-document-text-data\")\n",
    "ds = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5735275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_id': Value(dtype='string', id=None),\n",
       " 'document_metadata.collection_summary': Value(dtype='string', id=None),\n",
       " 'document_metadata.collection_title': Value(dtype='string', id=None),\n",
       " 'document_metadata.corpus_type_name': Value(dtype='string', id=None),\n",
       " 'document_metadata.corpus_import_id': Value(dtype='string', id=None),\n",
       " 'document_metadata.category': Value(dtype='string', id=None),\n",
       " 'document_metadata.description': Value(dtype='string', id=None),\n",
       " 'document_metadata.document_title': Value(dtype='string', id=None),\n",
       " 'document_metadata.family_import_id': Value(dtype='string', id=None),\n",
       " 'document_metadata.family_slug': Value(dtype='string', id=None),\n",
       " 'document_metadata.geographies': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'document_metadata.import_id': Value(dtype='string', id=None),\n",
       " 'document_metadata.languages': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'document_metadata.metadata': {'author': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'author_type': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'framework': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'hazard': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'instrument': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'keyword': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'sector': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       "  'topic': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)},\n",
       " 'document_metadata.family_title': Value(dtype='string', id=None),\n",
       " 'document_metadata.publication_ts': Value(dtype='string', id=None),\n",
       " 'document_metadata.slug': Value(dtype='string', id=None),\n",
       " 'document_metadata.source': Value(dtype='string', id=None),\n",
       " 'document_metadata.source_url': Value(dtype='string', id=None),\n",
       " 'document_metadata.type': Value(dtype='string', id=None),\n",
       " 'document_cdn_object': Value(dtype='string', id=None),\n",
       " 'document_content_type': Value(dtype='string', id=None),\n",
       " 'document_md5_sum': Value(dtype='string', id=None),\n",
       " 'languages': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'document_metadata.translated': Value(dtype='bool', id=None),\n",
       " 'pdf_data_page_metadata.dimensions': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " '_html_data.detected_title': Value(dtype='string', id=None),\n",
       " '_html_data.detected_date': Value(dtype='string', id=None),\n",
       " '_html_data.has_valid_text': Value(dtype='bool', id=None),\n",
       " 'pipeline_metadata.parser_metadata': {'azure_api_version': Value(dtype='string', id=None),\n",
       "  'azure_model_id': Value(dtype='string', id=None),\n",
       "  'parsing_date': Value(dtype='string', id=None)},\n",
       " 'text_block.text_block_id': Value(dtype='string', id=None),\n",
       " 'text_block.language': Value(dtype='string', id=None),\n",
       " 'text_block.type': Value(dtype='string', id=None),\n",
       " 'text_block.type_confidence': Value(dtype='float64', id=None),\n",
       " 'text_block.coords': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'text_block.page_number': Value(dtype='int64', id=None),\n",
       " 'text_block.text': Value(dtype='string', id=None),\n",
       " 'text_block.index': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad46e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ds = ds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91f6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "<class 'bool'>\n",
      "<class 'list'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "<class 'str'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for key in flat_ds.features.keys():\n",
    "    print(type(flat_ds[18:19][key][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3982d64",
   "metadata": {},
   "source": [
    "## Save 100000 chunks in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf79a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv # This loads the .env file into os.environ\n",
    "batch_df = pd.DataFrame(flat_ds[:100000])\n",
    "# Set up the database connection using SQLAlchemy\n",
    "engine = create_engine(os.getenv(\"DB_URL\"))\n",
    "\n",
    "# Write the pandas DataFrame to the PostgreSQL database\n",
    "batch_df.to_sql('climate_policy_radar', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f90c8",
   "metadata": {},
   "source": [
    "## Attempt to change arrays to strings for entire dataset\n",
    "\n",
    "Just keeping this here for future reference. I don't think it's needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_string(batch):\n",
    "    keys_to_process = [\n",
    "        \"document_metadata.geographies\",\n",
    "        \"document_metadata.languages\",\n",
    "        \"languages\",\n",
    "        \"pdf_data_page_metadata.dimensions\",\n",
    "        \"text_block.coords\"\n",
    "    ]\n",
    "    for key in keys_to_process:\n",
    "        # Convert numpy arrays to lists\n",
    "        batch[key] = [str(x) for x in batch[key]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf46f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataset. This takes the longest time\n",
    "flat_ds = flat_ds.map(array_to_string, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabedc82",
   "metadata": {},
   "source": [
    "## Read the data from the database\n",
    "\n",
    "So it's easier to access the data in case the kernel crashes and had to re-run the codes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19defae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_metadata.collection_summary</th>\n",
       "      <th>document_metadata.collection_title</th>\n",
       "      <th>document_metadata.corpus_type_name</th>\n",
       "      <th>document_metadata.corpus_import_id</th>\n",
       "      <th>document_metadata.category</th>\n",
       "      <th>document_metadata.description</th>\n",
       "      <th>document_metadata.document_title</th>\n",
       "      <th>document_metadata.family_import_id</th>\n",
       "      <th>document_metadata.family_slug</th>\n",
       "      <th>...</th>\n",
       "      <th>pipeline_metadata.parser_metadata.azure_model_id</th>\n",
       "      <th>pipeline_metadata.parser_metadata.parsing_date</th>\n",
       "      <th>text_block.text_block_id</th>\n",
       "      <th>text_block.language</th>\n",
       "      <th>text_block.type</th>\n",
       "      <th>text_block.type_confidence</th>\n",
       "      <th>text_block.coords</th>\n",
       "      <th>text_block.page_number</th>\n",
       "      <th>text_block.text</th>\n",
       "      <th>text_block.index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>title</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{70.452,123.7392},{524.1816,123.7392},{524.18...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Draft of the National Energy and Climate Plan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{69.7176,208.4256},{124.21440000000001,208.79...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{217.1952,685.1376},{286.1856,685.1376},{286....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>REPUBLIKA SHOIPERISE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{195.2928,690.6096},{308.448,690.6096},{308.4...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MINISTRIA E TURIZMIT DHE MJEDISIT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{76.9968,708.5015999999999},{182.88,708.1344}...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MINISTRIA E INFRASTRUKTURĒS DHE ENERGJISE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document_id document_metadata.collection_summary  \\\n",
       "0  CCLW.document.i00000002.n0000                                 None   \n",
       "1  CCLW.document.i00000002.n0000                                 None   \n",
       "2  CCLW.document.i00000002.n0000                                 None   \n",
       "3  CCLW.document.i00000002.n0000                                 None   \n",
       "4  CCLW.document.i00000002.n0000                                 None   \n",
       "\n",
       "  document_metadata.collection_title document_metadata.corpus_type_name  \\\n",
       "0                               None                  Laws and Policies   \n",
       "1                               None                  Laws and Policies   \n",
       "2                               None                  Laws and Policies   \n",
       "3                               None                  Laws and Policies   \n",
       "4                               None                  Laws and Policies   \n",
       "\n",
       "  document_metadata.corpus_import_id document_metadata.category  \\\n",
       "0        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "1        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "2        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "3        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "4        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "\n",
       "                       document_metadata.description  \\\n",
       "0  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "1  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "2  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "3  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "4  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "\n",
       "               document_metadata.document_title  \\\n",
       "0  National Energy and Climate Plan 2019 Draft    \n",
       "1  National Energy and Climate Plan 2019 Draft    \n",
       "2  National Energy and Climate Plan 2019 Draft    \n",
       "3  National Energy and Climate Plan 2019 Draft    \n",
       "4  National Energy and Climate Plan 2019 Draft    \n",
       "\n",
       "  document_metadata.family_import_id          document_metadata.family_slug  \\\n",
       "0        CCLW.family.i00000001.n0000  national-energy-and-climate-plan_8a4f   \n",
       "1        CCLW.family.i00000001.n0000  national-energy-and-climate-plan_8a4f   \n",
       "2        CCLW.family.i00000001.n0000  national-energy-and-climate-plan_8a4f   \n",
       "3        CCLW.family.i00000001.n0000  national-energy-and-climate-plan_8a4f   \n",
       "4        CCLW.family.i00000001.n0000  national-energy-and-climate-plan_8a4f   \n",
       "\n",
       "   ... pipeline_metadata.parser_metadata.azure_model_id  \\\n",
       "0  ...                                prebuilt-document   \n",
       "1  ...                                prebuilt-document   \n",
       "2  ...                                prebuilt-document   \n",
       "3  ...                                prebuilt-document   \n",
       "4  ...                                prebuilt-document   \n",
       "\n",
       "  pipeline_metadata.parser_metadata.parsing_date text_block.text_block_id  \\\n",
       "0                     2023-12-11T11:43:23.509480                        0   \n",
       "1                     2023-12-11T11:43:23.509480                        1   \n",
       "2                     2023-12-11T11:43:23.509480                        2   \n",
       "3                     2023-12-11T11:43:23.509480                        3   \n",
       "4                     2023-12-11T11:43:23.509480                        4   \n",
       "\n",
       "  text_block.language text_block.type text_block.type_confidence  \\\n",
       "0                  en           title                        1.0   \n",
       "1                  en            Text                        1.0   \n",
       "2                  en            Text                        1.0   \n",
       "3                  en            Text                        1.0   \n",
       "4                  en            Text                        1.0   \n",
       "\n",
       "                                   text_block.coords text_block.page_number  \\\n",
       "0  {{70.452,123.7392},{524.1816,123.7392},{524.18...                    0.0   \n",
       "1  {{69.7176,208.4256},{124.21440000000001,208.79...                    0.0   \n",
       "2  {{217.1952,685.1376},{286.1856,685.1376},{286....                    0.0   \n",
       "3  {{195.2928,690.6096},{308.448,690.6096},{308.4...                    0.0   \n",
       "4  {{76.9968,708.5015999999999},{182.88,708.1344}...                    0.0   \n",
       "\n",
       "                                     text_block.text text_block.index  \n",
       "0  Draft of the National Energy and Climate Plan ...                0  \n",
       "1                                          July 2021                1  \n",
       "2                               REPUBLIKA SHOIPERISE                2  \n",
       "3                  MINISTRIA E TURIZMIT DHE MJEDISIT                3  \n",
       "4          MINISTRIA E INFRASTRUKTURĒS DHE ENERGJISE                4  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the table\n",
    "df = pd.read_sql(\"SELECT * FROM climate_policy_radar\", engine)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ce453",
   "metadata": {},
   "source": [
    "# 2. Embeddings generation\n",
    "\n",
    "## 2.1 Load climateBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00dd9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_LOCAL_DIR = os.getenv('EMBEDDING_MODEL_LOCAL_DIR')\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9333973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arielliu/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:778: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/arielliu/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Download\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "\n",
    "# Save it to a  local_models folder\n",
    "tokenizer.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "model.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df923544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at local_model/climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "model = AutoModel.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58698bc0",
   "metadata": {},
   "source": [
    "### Checking existing documents' country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cf481da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   document_metadata.geographies\n",
      "0                          {SRB}\n",
      "1                          {MKD}\n",
      "2                          {GBR}\n",
      "3                          {TUV}\n",
      "4                          {FRA}\n",
      "5                          {ALB}\n",
      "6                          {EUR}\n",
      "7                          {MNE}\n",
      "8                          {AZE}\n",
      "9                          {CAN}\n",
      "10                         {JPN}\n",
      "11                         {BRA}\n",
      "12                         {DEU}\n",
      "13                         {XKX}\n",
      "14                         {CHN}\n",
      "15                         {ZAF}\n",
      "16                         {BIH}\n",
      "17                         {IRL}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT \"document_metadata.geographies\"\n",
    "FROM climate_policy_radar\n",
    "WHERE \"document_metadata.geographies\" IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "geos = pd.read_sql(query, engine)\n",
    "print(geos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfdfcd7",
   "metadata": {},
   "source": [
    "### Attempt to select only documents by Albania\n",
    "Testing using Albania for now - This takes a really long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c6a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering for ALB: 100%|██████████| 100000/100000 [00:00<00:00, 173917.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# This one worked\n",
    "from tqdm import tqdm\n",
    "\n",
    "geos = df[\"document_metadata.geographies\"]\n",
    "filter = [\"ALB\" in str(x) for x in tqdm(geos, desc=\"Filtering for ALB\")]\n",
    "alb_chunks = df[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "066f56a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_metadata.geographies</th>\n",
       "      <th>text_block.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>Draft of the National Energy and Climate Plan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>July 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>REPUBLIKA SHOIPERISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>MINISTRIA E TURIZMIT DHE MJEDISIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>MINISTRIA E INFRASTRUKTURĒS DHE ENERGJISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>german cooperation DEUTSCHE ZUSAMMENARBEIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>Implemented by giz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>Deutsche Gesellschaft Für Internationale Zusam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>Responsible for this document: Ministry of Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>{ALB}</td>\n",
       "      <td>Purpose of this document: Submission to Energy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document_id document_metadata.geographies  \\\n",
       "0  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "1  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "2  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "3  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "4  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "5  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "6  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "7  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "8  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "9  CCLW.document.i00000002.n0000                         {ALB}   \n",
       "\n",
       "                                     text_block.text  \n",
       "0  Draft of the National Energy and Climate Plan ...  \n",
       "1                                          July 2021  \n",
       "2                               REPUBLIKA SHOIPERISE  \n",
       "3                  MINISTRIA E TURIZMIT DHE MJEDISIT  \n",
       "4          MINISTRIA E INFRASTRUKTURĒS DHE ENERGJISE  \n",
       "5         german cooperation DEUTSCHE ZUSAMMENARBEIT  \n",
       "6                                 Implemented by giz  \n",
       "7  Deutsche Gesellschaft Für Internationale Zusam...  \n",
       "8  Responsible for this document: Ministry of Inf...  \n",
       "9  Purpose of this document: Submission to Energy...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alb_chunks[[\"document_id\", \"document_metadata.geographies\", \"text_block.text\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b691ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#took too long for me\n",
    "#DOUBLE CHECK LATER\n",
    "\n",
    "filter = flat_ds[\"document_metadata.geographies\"].astype(str).progress_apply(\n",
    "    lambda x: bool(re.search(r\"ALB\", x))\n",
    ")\n",
    "alb_chunks = flat_ds[filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ece61",
   "metadata": {},
   "source": [
    "## 2.2 Save embeddings in csv\n",
    "Embeddings generated in batches of 1000 chunks.\n",
    "Note: obsolete, just ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92703641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9f43e428cf4099a63d06db77f2f2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13df9e51743846abb9fb96770c7cad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caabfc0b6eef434cb7f3f43d582f7ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure the \"data\" directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Process embeddings in batches of 1000\n",
    "batch_size = 1000\n",
    "all_batches = (len(flat_ds) + batch_size - 1) // batch_size  # Calculate the number of batches\n",
    "num_batches = 2\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(flat_ds))\n",
    "    \n",
    "    # Generate embeddings for the current batch\n",
    "    batch_embeddings = flat_ds[start_idx:end_idx][\"text_block.text\"].progress_apply(\n",
    "        lambda text: generate_embeddings_for_text(text, model, tokenizer)\n",
    "    )\n",
    "    \n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "# Create a DataFrame for all embeddings\n",
    "embeddings_df = pd.DataFrame({\n",
    "    \"document_id\": flat_ds[:num_batches*1000][\"document_id\"],\n",
    "    \"embeddings\": all_embeddings\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a single CSV file\n",
    "embeddings_df.to_csv(\"data/embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356f563",
   "metadata": {},
   "source": [
    "Use DPR for question answering, using chunks[\"text_block.text\"] as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb0720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e574c6ec90de4480a3e39a4c5707a159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   7%|▋         | 1/14 [00:37<08:07, 37.52s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9a3012fc934f6d89193b142a01e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  14%|█▍        | 2/14 [01:22<08:22, 41.87s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05ca3da4ee64c33b5724190358bc337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  21%|██▏       | 3/14 [01:51<06:37, 36.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbac03410a4798913fab894c048178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  29%|██▊       | 4/14 [02:19<05:27, 32.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ef788812af46a7a2b7ee7c26b517f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  36%|███▌      | 5/14 [02:44<04:29, 29.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dd73fc6d03458289fb540277b20a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  43%|████▎     | 6/14 [03:10<03:49, 28.74s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccf9fde10bb4e5db06fc91cdcef30e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  50%|█████     | 7/14 [03:33<03:06, 26.63s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e44091b697d4c6e9bf8090003b6d89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  57%|█████▋    | 8/14 [03:53<02:28, 24.78s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fa38c71ab346119c86cbb7fbe74eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  64%|██████▍   | 9/14 [04:16<02:00, 24.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c8b8775b674d8d8998e48257f7434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  71%|███████▏  | 10/14 [04:37<01:32, 23.09s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b685bbfd75b14088b6d65a3deb8c2a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  79%|███████▊  | 11/14 [04:58<01:07, 22.45s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e910b3d22581424caf920dab5d3a8565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  86%|████████▌ | 12/14 [05:19<00:43, 21.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640f109b57b2423791ec79b53805ff1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:  93%|█████████▎| 13/14 [05:39<00:21, 21.55s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce01e18600d4f64b77f20cdc0078a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 14/14 [06:04<00:00, 26.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the \"data\" directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Use the filtered dataset, can add more columns if need to, for now only texts and doc_ids are present\n",
    "texts = alb_chunks[\"text_block.text\"]\n",
    "doc_ids = alb_chunks[\"document_id\"]\n",
    "\n",
    "# Batch processing setup\n",
    "batch_size = 1000\n",
    "num_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "all_embeddings = []\n",
    "all_doc_ids = []\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Embeddings\"):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(texts))\n",
    "    \n",
    "    batch_texts = texts.iloc[start_idx:end_idx]\n",
    "    batch_ids = doc_ids.iloc[start_idx:end_idx]\n",
    "    \n",
    "    batch_embeddings = batch_texts.progress_apply(\n",
    "        lambda text: generate_embeddings_for_text(text, model, tokenizer)\n",
    "    )\n",
    "    \n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "    all_doc_ids.extend(batch_ids)\n",
    "\n",
    "# Create a DataFrame for all embeddings\n",
    "embeddings_df = pd.DataFrame({\n",
    "    \"document_id\": all_doc_ids,\n",
    "    \"embedding\": all_embeddings\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "embeddings_df.to_csv(\"data/albania_embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5910cda",
   "metadata": {},
   "source": [
    "### Embedding all existing documents\n",
    "\n",
    "Now that I've tested with Albania and it worked, I'll generate embeddings with all documents and save them into csv files first. I will then save them into the database.\n",
    "\n",
    "This block of code takes a long time. It's a replication of the code for Albania but ensures each csv file has the country name and embeddings for that specific country is saved into their respective csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1cbbcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   0%|          | 0/14 [12:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m batch_ids = doc_ids.iloc[start_idx:end_idx].tolist()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Call the embedding function on the whole batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m batch_embeddings = \u001b[43mgenerate_embeddings_for_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m all_embeddings.extend(batch_embeddings)\n\u001b[32m     27\u001b[39m all_doc_ids.extend(batch_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/functions.py:38\u001b[39m, in \u001b[36mgenerate_embeddings_for_text\u001b[39m\u001b[34m(texts, model, tokenizer)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Get model output (without gradient calculation for efficiency)\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     model_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Use the CLS token embedding as the sentence embedding\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# This is a simple approach - in practice, you might use more sophisticated pooling\u001b[39;00m\n\u001b[32m     42\u001b[39m sentence_embeddings = model_output.last_hidden_state[:, \u001b[32m0\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    823\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    825\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    826\u001b[39m     input_ids=input_ids,\n\u001b[32m    827\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    830\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    831\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    845\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[39m, in \u001b[36mRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    510\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    511\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    512\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    518\u001b[39m         output_attentions,\n\u001b[32m    519\u001b[39m     )\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:452\u001b[39m, in \u001b[36mRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    449\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    450\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/pytorch_utils.py:238\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:464\u001b[39m, in \u001b[36mRobertaLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:362\u001b[39m, in \u001b[36mRobertaIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/group-6-final-project/project-env/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Ensure the \"data\" directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Use the filtered dataset\n",
    "texts = alb_chunks[\"text_block.text\"]\n",
    "doc_ids = alb_chunks[\"document_id\"]\n",
    "\n",
    "# Batch processing setup\n",
    "batch_size = 1000\n",
    "num_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "all_embeddings = []\n",
    "all_doc_ids = []\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Generating Embeddings\"):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(texts))\n",
    "    \n",
    "    # Extract batch slices\n",
    "    batch_texts = texts.iloc[start_idx:end_idx].tolist()\n",
    "    batch_ids = doc_ids.iloc[start_idx:end_idx].tolist()\n",
    "    \n",
    "    # Call the embedding function on the whole batch\n",
    "    batch_embeddings = generate_embeddings_for_text(batch_texts, model, tokenizer)\n",
    "    \n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "    all_doc_ids.extend(batch_ids)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "embeddings_df = pd.DataFrame({\n",
    "    \"document_id\": all_doc_ids,\n",
    "    \"embedding\": all_embeddings\n",
    "})\n",
    "\n",
    "embeddings_df.to_csv(\"data/albania_embeddings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e57c87",
   "metadata": {},
   "source": [
    "# 3. Saving the embeddings into the database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
